# run_bots.py
#!/usr/bin/env python
"""
The Closer Worker - –° –ü–û–î–î–ï–†–ñ–ö–û–ô –ù–û–í–û–ì–û API –∏ –ø–µ—Ä–µ–¥–∞—á–µ–π –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞
"""
import asyncio
import os
import sys
import django
import logging
import random
from asgiref.sync import sync_to_async
import json
import threading
from http.server import HTTPServer, BaseHTTPRequestHandler

# --- DUMMY SERVER –¥–ª—è Health Checks (Render/Railway) ---
class SimpleHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        self.send_response(200)
        self.end_headers()
        self.wfile.write(b"Bot is running!")

def start_dummy_server():
    port = int(os.environ.get("PORT", 10000))
    server = HTTPServer(('0.0.0.0', port), SimpleHandler)
    print(f"üåç Dummy server listening on port {port}")
    server.serve_forever()

threading.Thread(target=start_dummy_server, daemon=True).start()

# --- DJANGO SETUP ---
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'config.settings')
django.setup()

from django.utils import timezone
from core.models import BotAgent, Conversation, Message as MessageModel
from services.rag_service import rag_service

from telethon import TelegramClient, events, functions
from telethon.sessions import StringSession

try:
    from openai import OpenAI, OpenAIError
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("‚ö†Ô∏è –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ openai –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")

# --- LOGGING ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger("BotWorker")

# --- OPENAI SETUP ---
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
ai_client = None

if OPENAI_AVAILABLE and OPENAI_API_KEY:
    try:
        ai_client = OpenAI(api_key=OPENAI_API_KEY)
        logger.info("‚úÖ OpenAI client initialized")
    except Exception as e:
        logger.error(f"‚ùå Failed to initialize OpenAI: {e}")
elif not OPENAI_API_KEY:
    logger.warning("‚ö†Ô∏è OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env")

active_clients = {}

# --- PROMPT TEMPLATES ---
HUMANIZER_INSTRUCTIONS_TEMPLATE = """
–†–æ–ª—å: –¢—ã ‚Äî {bot_name}, —Å–æ—Ç—Ä—É–¥–Ω–∏–∫ {company_name}. –ü–∏—à–µ—à—å —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞ –≤ Telegram.
–ó–∞–¥–∞—á–∞: –†–µ—à–∏—Ç—å –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –ø—Ä–æ–¥–∞—Ç—å.

–°–¢–ò–õ–¨ (–°–¢–†–û–ì–û):
1. **–§–æ—Ä–º–∞—Ç:** –ü–∏—à–∏ –ø—Ä–µ–¥–µ–ª—å–Ω–æ –∫—Ä–∞—Ç–∫–æ. –ò–∑–±–µ–≥–∞–π —Å–ø–∏—Å–∫–æ–≤. –ö–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–∑—ã ‚Äî –±–µ–∑ —Ç–æ—á–∫–∏ –≤ –∫–æ–Ω—Ü–µ, –º–æ–∂–Ω–æ —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã.
2. **–¢–∞–±—É:** –ó–ê–ü–†–ï–©–ï–ù–û –ø–∏—Å–∞—Ç—å "–Ø –ò–ò", "–Ø–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å", "–ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?".
3. **–†–µ–∞–∫—Ü–∏—è:** –ù–∞ "–ü—Ä–∏–≤–µ—Ç" –æ—Ç–≤–µ—á–∞–π "–ü—Ä–∏–≤–µ—Ç" –∏–ª–∏ "–ù–∞ —Å–≤—è–∑–∏". –ù–µ –∑–∞–¥–∞–≤–∞–π –≤–æ–ø—Ä–æ—Å–æ–≤, –ø–æ–∫–∞ –Ω–µ –ø–æ–π–º–µ—à—å —Å—É—Ç—å.
4. **–ö–æ–Ω–∫—Ä–µ—Ç–∏–∫–∞:** –ù–µ –∑–µ—Ä–∫–∞–ª—å –≤–æ–ø—Ä–æ—Å (User: "–¶–µ–Ω–∞?" -> Bot: "5000", –∞ –Ω–µ "–¶–µ–Ω–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç...").

–í–µ–¥–∏ —Å–µ–±—è –∫–∞–∫ –∑–∞–Ω—è—Ç–æ–π —á–µ–ª–æ–≤–µ–∫, –∞ –Ω–µ –∫–∞–∫ —É—Å–ª—É–∂–ª–∏–≤—ã–π —Ä–æ–±–æ—Ç.
"""

# --- DATABASE HELPERS ---

@sync_to_async
def get_active_bots_from_db():
    return list(BotAgent.objects.filter(
        platform='telegram',
        status='active'
    ).exclude(session_string='').exclude(session_string__isnull=True))

@sync_to_async
def get_bot_by_id(bot_id):
    try:
        return BotAgent.objects.get(id=bot_id)
    except BotAgent.DoesNotExist:
        return None

@sync_to_async
def get_or_create_conversation(bot_instance, user_id, user_name):
    conversation, created = Conversation.objects.get_or_create(
        bot=bot_instance,
        user_id=user_id,
        defaults={
            'user_name': user_name,
            'started_at': timezone.now()
        }
    )
    conversation.last_message_at = timezone.now()
    conversation.save(update_fields=['last_message_at'])
    return conversation

@sync_to_async
def save_message_to_db(conversation, role, content):
    return MessageModel.objects.create(
        conversation=conversation,
        role=role,
        content=content
    )

@sync_to_async
def mark_bot_invalid(bot_id):
    BotAgent.objects.filter(id=bot_id).update(status='error')

@sync_to_async
def get_conversation_history(conversation_id, limit=10):
    messages = MessageModel.objects.filter(conversation_id=conversation_id).order_by('-created_at')[:limit]
    history_objs = list(reversed(messages))
    
    formatted_history = []
    for msg in history_objs:
        role = 'assistant' if msg.role == 'bot' else 'user'
        formatted_history.append({'role': role, 'content': msg.content})
        
    return formatted_history

@sync_to_async
def get_rag_response(bot_id, query):
    try:
        result = rag_service.answer_question(bot_id, query, top_k=5)
        return result
    except Exception as e:
        logger.error(f"RAG Error for bot {bot_id}: {e}")
        return {
            'answer': None,
            'sources': [],
            'confidence': 0.0
        }

# --- AI CORE LOGIC ---

async def get_chatgpt_response(message_text, bot_record, history=None, conversation_id=None, telegram_client=None):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Function Calling –∏ Humanizer.
    telegram_client: –ê–∫—Ç–∏–≤–Ω–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –±–µ–∑ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤.
    """
    if not ai_client:
        return "‚ö†Ô∏è –û—à–∏–±–∫–∞: AI –∫–ª–∏–µ–Ω—Ç –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω."

    try:
        from core.models import BotFunction
        from services.functions_service import functions_service
        
        # 1. Humanizer (–õ–∏—á–Ω–æ—Å—Ç—å –±–æ—Ç–∞)
        humanizer = HUMANIZER_INSTRUCTIONS_TEMPLATE.format(
            bot_name=bot_record.name,
            company_name=bot_record.company_name or "TheCloser"
        )
        
        user_prompt = bot_record.system_prompt or ""
        
        # 2. RAG (–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π)
        rag_context = ""
        if bot_record.use_rag:
            logger.info(f"üîç [Bot {bot_record.id}] Searching knowledge base...")
            rag_result = await get_rag_response(bot_record.id, message_text)
            
            if rag_result and rag_result.get('answer'):
                rag_context = f"\n\nüìö –ò–ù–§–û–†–ú–ê–¶–ò–Ø –ò–ó –ë–ê–ó–´ –ó–ù–ê–ù–ò–ô:\n{rag_result['answer']}\n"
                logger.info(f"‚úÖ [Bot {bot_record.id}] RAG found info")
        
        # 3. –°–±–æ—Ä–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
        final_system_prompt = humanizer + "\n\n" + user_prompt
        if rag_context:
            final_system_prompt += "\n\n–í–ê–ñ–ù–û: –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –¥–ª—è –æ—Ç–≤–µ—Ç–∞."
            final_system_prompt += rag_context
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π
        messages_payload = [{"role": "system", "content": final_system_prompt}]
        
        if history:
            msgs_to_add = history
            # –ò—Å–∫–ª—é—á–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω–æ —É–∂–µ —Ç–∞–º
            if history and history[-1]['role'] == 'user' and history[-1]['content'] == message_text:
                msgs_to_add = history[:-1]
            messages_payload.extend(msgs_to_add)
        
        messages_payload.append({"role": "user", "content": message_text})
        
        # 4. –ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ (Functions)
        bot_functions = await sync_to_async(list)(
            BotFunction.objects.filter(bot=bot_record, is_active=True)
        )
        tools = [func.to_openai_tool() for func in bot_functions]
        
        logger.info(f"[Bot {bot_record.name}] Model: {bot_record.openai_model} | Tools: {len(tools)}")
        
        loop = asyncio.get_event_loop()
        uses_new_api = bot_record.uses_new_api()
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã API –∑–∞–ø—Ä–æ—Å–∞
        api_params = {
            "model": bot_record.openai_model,
            "messages": messages_payload,
        }
        if tools:
            api_params["tools"] = tools
            api_params["tool_choice"] = "auto"
            
        if not uses_new_api:
             api_params["temperature"] = bot_record.temperature
             api_params["max_tokens"] = bot_record.max_tokens

        # 5. –ü–ï–†–í–´–ô –ó–ê–ü–†–û–° –ö OPENAI
        response = await loop.run_in_executor(
            None,
            lambda: ai_client.chat.completions.create(**api_params)
        )
        
        message = response.choices[0].message
        
        # 6. –û–ë–†–ê–ë–û–¢–ö–ê FUNCTION CALLING
        if message.tool_calls:
            logger.info(f"üîß [Bot {bot_record.id}] AI wants to call {len(message.tool_calls)} function(s)")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞–º–µ—Ä–µ–Ω–∏–µ AI –≤ –∏—Å—Ç–æ—Ä–∏—é (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è API)
            messages_payload.append(message)
            
            for tool_call in message.tool_calls:
                function_name = tool_call.function.name
                function_args = json.loads(tool_call.function.arguments)
                
                logger.info(f"‚öôÔ∏è Calling: {function_name} with {function_args}")
                
                # –í–´–ü–û–õ–ù–Ø–ï–ú –§–£–ù–ö–¶–ò–Æ (–ü–µ—Ä–µ–¥–∞–µ–º –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞!)
                result = await functions_service.execute_function(
                    bot_record.id,
                    conversation_id,
                    function_name,
                    function_args,
                    client=telegram_client  # <--- –ü–ï–†–ï–î–ê–ï–ú –¢–†–£–ë–ö–£
                )
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é
                messages_payload.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "name": function_name,
                    "content": json.dumps(result, ensure_ascii=False)
                })
            
            # 7. –í–¢–û–†–û–ô –ó–ê–ü–†–û–° –ö OPENAI (–§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç)
            final_api_params = {
                "model": bot_record.openai_model,
                "messages": messages_payload
            }
            if not uses_new_api:
                final_api_params["temperature"] = bot_record.temperature
                final_api_params["max_tokens"] = bot_record.max_tokens
                
            final_response = await loop.run_in_executor(
                None,
                lambda: ai_client.chat.completions.create(**final_api_params)
            )
            
            return final_response.choices[0].message.content.strip()
        
        return message.content.strip()
        
    except Exception as e:
        logger.error(f"OpenAI Error: {e}")
        return "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è —Å–µ–π—á–∞—Å –Ω–µ –º–æ–≥—É –æ—Ç–≤–µ—Ç–∏—Ç—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."


# --- TELETHON HANDLERS ---

async def keep_online_loop(client, bot_name):
    while True:
        try:
            await client(functions.account.UpdateStatusRequest(offline=False))
        except Exception as e:
            logger.error(f"[{bot_name}] Failed to update status: {e}")
        
        await asyncio.sleep(300 + random.randint(0, 10))


async def handle_message(event, bot_id):
    bot_record = await get_bot_by_id(bot_id)
    if not bot_record or bot_record.status != 'active':
        return

    sender = await event.get_sender()
    user_id = str(sender.id)
    user_name = f"{sender.first_name or ''} {sender.last_name or ''}".strip() or "Unknown"
    text = event.message.text

    if not text:
        return

    logger.info(f"üì® [{bot_record.name}] New msg from {user_name}: {text[:50]}...")

    # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –ø–æ–ª—É—á–∞–µ–º –¥–∏–∞–ª–æ–≥
    conversation = await get_or_create_conversation(bot_record, user_id, user_name)
    await save_message_to_db(conversation, 'user', text)    
    
    history = await get_conversation_history(conversation.id, limit=11)

    read_delay = 2 + random.randint(0, 3)
    await asyncio.sleep(read_delay)

    try:
        await event.message.mark_read()
    except:
        pass
    
    # –ü–ï–†–ï–î–ê–ï–ú conversation.id –∏ active client –í –§–£–ù–ö–¶–ò–Æ –ì–ï–ù–ï–†–ê–¶–ò–ò
    response_text = await get_chatgpt_response(
        text, 
        bot_record,
        history=history,
        conversation_id=conversation.id,
        telegram_client=event.client  # <--- –ë–ï–†–ï–ú –ö–õ–ò–ï–ù–¢–ê –ò–ó –°–û–ë–´–¢–ò–Ø
    )

    typing_speed = random.randint(5, 8)
    typing_duration = len(response_text) / typing_speed
    typing_duration = max(2.0, min(15.0, typing_duration))

    try:
        async with event.client.action(event.chat_id, 'typing'):
            await asyncio.sleep(typing_duration)
    except:
        await asyncio.sleep(typing_duration)

    await event.reply(response_text)
    
    await save_message_to_db(conversation, 'bot', response_text)
    
    logger.info(f"‚úÖ [{bot_record.name}] Replied to {user_name}")


async def start_single_bot(bot_record):
    try:
        api_id = int(bot_record.api_id)
        api_hash = bot_record.api_hash
        session_str = bot_record.session_string

        client = TelegramClient(StringSession(session_str), api_id, api_hash)
        
        await client.connect()
        
        if not await client.is_user_authorized():
            logger.error(f"‚ùå Bot [{bot_record.name}] session invalid")
            await mark_bot_invalid(bot_record.id)
            return

        @client.on(events.NewMessage(incoming=True, func=lambda e: e.is_private))
        async def wrapper(event, b_id=bot_record.id):
            await handle_message(event, b_id)

        online_task = asyncio.create_task(keep_online_loop(client, bot_record.name))
        
        active_clients[bot_record.id] = {
            'client': client,
            'tasks': [online_task]
        }
        
        me = await client.get_me()
        rag_status = "‚úÖ RAG ON" if bot_record.use_rag else "‚ùå RAG OFF"
        api_type = "üß† NEW API" if bot_record.uses_new_api() else "üîß LEGACY API"
        logger.info(f"üöÄ Bot started: {bot_record.name} (@{me.username}) | {bot_record.openai_model} | {api_type} | {rag_status}")

    except Exception as e:
        logger.error(f"‚ùå Error starting bot {bot_record.name}: {e}")


async def stop_single_bot(bot_id):
    if bot_id in active_clients:
        data = active_clients[bot_id]
        
        for task in data.get('tasks', []):
            task.cancel()
        
        client = data['client']
        await client.disconnect()
        
        del active_clients[bot_id]
        logger.info(f"üõë Bot ID {bot_id} stopped")


async def monitor_manager():
    logger.info("üëÄ Monitor Manager started...")
    logger.info(f"üìö RAG Service: {'‚úÖ Available' if rag_service else '‚ùå Not available'}")
    logger.info(f"ü§ñ HUMANIZER Instructions: ENABLED")
    logger.info(f"üÜï NEW API Support: o1/o3/GPT-5+")
    
    while True:
        try:
            db_bots = await get_active_bots_from_db()
            db_bot_ids = set(b.id for b in db_bots)
            running_ids = set(active_clients.keys())

            for bot_id in (db_bot_ids - running_ids):
                bot_obj = next(b for b in db_bots if b.id == bot_id)
                asyncio.create_task(start_single_bot(bot_obj))

            for bot_id in (running_ids - db_bot_ids):
                asyncio.create_task(stop_single_bot(bot_id))

        except Exception as e:
            logger.error(f"Monitor error: {e}")
        
        await asyncio.sleep(10)


if __name__ == "__main__":
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    
    try:
        loop.run_until_complete(monitor_manager())
    except KeyboardInterrupt:
        logger.info("üëã Shutting down...")
        pending = asyncio.all_tasks(loop)
        for task in pending:
            task.cancel()
        loop.run_until_complete(asyncio.gather(*pending, return_exceptions=True))